{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tacotron-data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEVacITmFFPwNrqemGY9hG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hourglasshoro/research-notebook/blob/main/tacotron_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejJ0m3ODih1a"
      },
      "source": [
        "#!unzip jsut_ver1.1.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDyVSBaMXp8S",
        "outputId": "fa94fbb1-4184-4399-d103-fe39aa5f9178"
      },
      "source": [
        "!apt install aptitude swig > /dev/null\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null\n",
        "!pip install mecab-python3==0.996.3 > /dev/null\n",
        "!pip install pykakasi > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 11.6M  100 11.6M    0     0  1643k      0  0:00:07  0:00:07 --:--:-- 2424k\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Conjunction.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Filler.csv \n",
            "rm ./Noun.place.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Others.csv \n",
            "rm ./Noun.proper.csv \n",
            "rm ./Noun.name.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "rm ./unk.def \n",
            "rm ./feature.def \n",
            "rm ./rewrite.def \n",
            "rm ./matrix.def \n",
            "rm ./char.def \n",
            "rm ./left-id.def \n",
            "rm ./right-id.def \n",
            "rm ./pos-id.def \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 32050    0 32050    0     0  22860      0 --:--:--  0:00:01 --:--:-- 22843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7pm9v_nkcJ1",
        "outputId": "31cdea0c-cc7e-4ac5-8c82-2671dbe2f91e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKyV15-aX68o"
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import MeCab\n",
        "import pykakasi.kakasi as kakasi\n",
        "\n",
        "def format_text(text):\n",
        "    text = unicodedata.normalize(\"NFKC\", text)  # 全角記号をざっくり半角へ置換（でも不完全）\n",
        "\n",
        "    # 記号を消し去るための魔法のテーブル作成\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation  + \"「」・\")\n",
        "    text = text.translate(table)\n",
        "    text = text.translate(str.maketrans({'、' : ',', '。' : '.'}))\n",
        "    return text\n",
        "\n",
        "def getPronunciation(text):\n",
        "    m_result = m.parse(text).splitlines() #mecabの解析結果の取得\n",
        "    m_result = m_result[:-1] #最後の1行は不要な行なので除く\n",
        "\n",
        "    pro = '' #発音文字列全体を格納する変数\n",
        "    for v in m_result:\n",
        "        if '\\t' not in v: continue\n",
        "        surface = v.split('\\t')[0] #表層形\n",
        "        p = v.split('\\t')[1].split(',')[-1] #発音を取得したいとき\n",
        "        #p = v.split('\\t')[1].split(',')[-2] #ルビを取得したいとき\n",
        "        #発音が取得できていないときsurfaceで代用\n",
        "        if p == '*':\n",
        "          p = surface\n",
        "        pro += p\n",
        "\n",
        "    pro = conv.do(pro) #ひらがなをカタカナに変換\n",
        "    pro = format_text(pro) #余計な記号を削除\n",
        "\n",
        "    return pro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M7A5U5ixW44"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "cmd = 'echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')\n",
        "m = MeCab.Tagger(\"-d {0}\".format(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQii33DuYBqC"
      },
      "source": [
        "kakasi = kakasi()\n",
        "kakasi.setMode(\"K\",\"a\")\n",
        "conv = kakasi.getConverter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5b-fopjYDq0",
        "outputId": "0bbc66ab-76f9-4f1b-d90e-130b126440eb"
      },
      "source": [
        "text = '水をマレーシアから買わなくてはならないのです。'\n",
        "print(text)\n",
        "print(getPronunciation(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "水をマレーシアから買わなくてはならないのです。\n",
            "mizu wo mareeshia kara kawa naku te wa nara nai no desu. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ntuYVaBr4Iz"
      },
      "source": [
        "baseUrl = '/content/drive/MyDrive/Research/dataset/jsut/jsut_ver1.1'\n",
        "datasetUrl = '/content/jsut_ver1.1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwaZFWVVskP0"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SszF7VVcs2R-"
      },
      "source": [
        "dirs = ['basic5000','precedent130','repeat500','voiceactress100','loanword128','travel1000','countersuffix26','onomatopee300','utparaphrase512']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ht53fbxrfTZ"
      },
      "source": [
        "out_path = os.path.join(baseUrl, \"filelist.txt\")\n",
        "with open(out_path, mode='w', encoding='utf-8') as fout:\n",
        "  for dir in dirs:\n",
        "    file_path = os.path.join(baseUrl,dir,'transcript_utf8.txt')\n",
        "    f = open(file_path, 'r', encoding='UTF-8')\n",
        "    datalist = f.readlines()\n",
        "    for data in datalist:\n",
        "      data = str.split(data,\":\")\n",
        "      wav_file = data[0] + '.wav'\n",
        "      wav_file = os.path.join(datasetUrl, dir, 'wav' ,wav_file)\n",
        "      text = getPronunciation(data[1])\n",
        "      fout.write(wav_file + '|' + text + '\\n')\n",
        "\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSndZ8iN3Njl"
      },
      "source": [
        "  file_path = os.path.join(baseUrl, \"filelist.txt\")\n",
        "  test_path = os.path.join(baseUrl, \"ljs_audio_text_test_filelist.txt\")\n",
        "  train_path = os.path.join(baseUrl, \"ljs_audio_text_train_filelist.txt\")\n",
        "  val_path = os.path.join(baseUrl, \"ljs_audio_text_val_filelist.txt\")\n",
        "  f = open(file_path, 'r', encoding='UTF-8')\n",
        "  datalist = f.readlines()\n",
        "  test_div = 10\n",
        "  with open(test_path, mode='w') as ftest, open(train_path, mode='w') as ftrain, open(val_path, mode='w') as fval:\n",
        "    for i, data in enumerate(datalist):\n",
        "      if i % test_div == 0:\n",
        "        if i % (test_div * 5) == 0:\n",
        "          fval.write(data)\n",
        "        else:\n",
        "          ftest.write(data)\n",
        "      else:\n",
        "        ftrain.write(data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}