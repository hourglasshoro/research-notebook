{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMovxzaV5J8HXsMUw+3M43A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63c3d94bc45e4ff9aefb48c287039ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0b6e014b638495f8e270ce3a51d737a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b48158f0a575484ab4fa9653b8a908cd",
              "IPY_MODEL_11c4b77f17264c7ab5f0f239851604b4"
            ]
          }
        },
        "d0b6e014b638495f8e270ce3a51d737a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b48158f0a575484ab4fa9653b8a908cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf37f7a103214c4f89b774029c68ae1a",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3539e3167353419bb626d6d88afaced4"
          }
        },
        "11c4b77f17264c7ab5f0f239851604b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a03bdd272e8941afb424fdd5ee94fe99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 198/198 [01:12&lt;00:00,  2.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8bef59f72de4183b3507d0a4aaf568e"
          }
        },
        "cf37f7a103214c4f89b774029c68ae1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3539e3167353419bb626d6d88afaced4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a03bdd272e8941afb424fdd5ee94fe99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8bef59f72de4183b3507d0a4aaf568e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKXBq7Brp41_"
      },
      "source": [
        "#"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_U9UWBdp5_-"
      },
      "source": [
        "```\n",
        "function ClickConnect(){\n",
        "    console.log(\"Working!\"); \n",
        "    document.querySelector(\"colab-run-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect, 60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJIsA_E2u3cM",
        "outputId": "76f4d54b-df7c-4ecd-eb6d-4471cad40882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr  7 10:53:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2-PHPPx0QTU",
        "outputId": "81d52685-cfad-462a-e213-af7632dc86b0"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP\" -O /content/dataset.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q /content/dataset.zip -d /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-07 08:40:17--  https://docs.google.com/uc?export=download&confirm=aYOV&id=1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.70.102, 74.125.70.113, 74.125.70.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.70.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e=download [following]\n",
            "--2021-04-07 08:40:17--  https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e=download\n",
            "Resolving doc-10-4s-docs.googleusercontent.com (doc-10-4s-docs.googleusercontent.com)... 74.125.69.132, 2607:f8b0:4001:c08::84\n",
            "Connecting to doc-10-4s-docs.googleusercontent.com (doc-10-4s-docs.googleusercontent.com)|74.125.69.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=o6pggpk0a6o46&continue=https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e%3Ddownload&hash=rqoael3m4q8iqhssj3jgvjpu8t57kdnf [following]\n",
            "--2021-04-07 08:40:17--  https://docs.google.com/nonceSigner?nonce=o6pggpk0a6o46&continue=https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e%3Ddownload&hash=rqoael3m4q8iqhssj3jgvjpu8t57kdnf\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.70.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e=download&nonce=o6pggpk0a6o46&user=03036451436857610424Z&hash=d02ijp44jk6a3p1toqd079uvi3621m49 [following]\n",
            "--2021-04-07 08:40:17--  https://doc-10-4s-docs.googleusercontent.com/docs/securesc/dv22vdji96tvhvpn6poarhb304n7dssb/36svs94vo19f8f4agglnet7vg6hkrktu/1617784800000/03816308716299652124/03036451436857610424Z/1-1ltDoEYlNzwRF84HMIcKbDucgmId3cP?e=download&nonce=o6pggpk0a6o46&user=03036451436857610424Z&hash=d02ijp44jk6a3p1toqd079uvi3621m49\n",
            "Connecting to doc-10-4s-docs.googleusercontent.com (doc-10-4s-docs.googleusercontent.com)|74.125.69.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/dataset.zip’\n",
            "\n",
            "/content/dataset.zi     [        <=>         ]   1.41G   182MB/s    in 9.0s    \n",
            "\n",
            "2021-04-07 08:40:26 (161 MB/s) - ‘/content/dataset.zip’ saved [1514979231]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk9fQfvfG5U6"
      },
      "source": [
        "!pip install pytorch_lightning neptune-client > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymlSMqc4jtg"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh5jKIKx4cKd"
      },
      "source": [
        "class InterjectionDataset(data.Dataset):\n",
        "  def __init__(self, dir_path, input_size, meta_df):\n",
        "    super().__init__()\n",
        "    self.dir_path = dir_path\n",
        "    self.input_size = input_size\n",
        "    self.meta_df = meta_df\n",
        "    self.len = len(self.meta_df)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    row = self.meta_df.iloc[index]\n",
        "    image_name = row.image\n",
        "    p = os.path.join(self.dir_path, image_name)\n",
        "    image = Image.open(p)\n",
        "    image = image.resize(self.input_size)\n",
        "    image = np.array(image)\n",
        "    image = image.reshape(512, 512, 1)\n",
        "    image = np.transpose(image, (2, 0, 1))\n",
        "    image = torch.from_numpy(image)\n",
        "    image = image.type(torch.FloatTensor)\n",
        "\n",
        "    start = row.start\n",
        "    end = row.end\n",
        "    label = np.zeros(512)\n",
        "    label[start:end] = 1\n",
        "    label = torch.from_numpy(label)\n",
        "    label = label.type(torch.FloatTensor)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9sHi9eZ7DMQ"
      },
      "source": [
        "dir_path = \"/content/content/dataset_image\"\n",
        "image_path = os.path.join(dir_path,\"image\")\n",
        "meta_path = os.path.join(dir_path,\"interjection_data.csv\")\n",
        "\n",
        "with open(meta_path, 'r', encoding='UTF-8') as csv:\n",
        "  meta_df = pd.read_csv(csv)\n",
        "  dataset = InterjectionDataset(image_path, (512,512), meta_df)\n",
        "\n",
        "test_size = int(len(dataset) * 0.2)\n",
        "valid_size = test_size\n",
        "train_size = len(dataset) - (test_size + valid_size)\n",
        "splited_dataset = data.random_split(dataset, [train_size, test_size, valid_size], generator=torch.Generator().manual_seed(0))\n",
        "train_dataset = splited_dataset[0]\n",
        "test_dataset = splited_dataset[1]\n",
        "valid_dataset = splited_dataset[2]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAOuG5B78tkO"
      },
      "source": [
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "  \"\"\"1x1 convolution\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                    padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion: int = 1\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    inplanes: int,\n",
        "    planes: int,\n",
        "    stride: int = 1,\n",
        "    downsample: Optional[nn.Module] = None,\n",
        "    groups: int = 1,\n",
        "    base_width: int = 64,\n",
        "    dilation: int = 1,\n",
        "    norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "  ) -> None:\n",
        "    super(BasicBlock, self).__init__()\n",
        "    if norm_layer is None:\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "    if groups != 1 or base_width != 64:\n",
        "        raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "    if dilation > 1:\n",
        "        raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = norm_layer(planes)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = norm_layer(planes)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tensor:\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "        identity = self.downsample(x)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9At8MDoPHIjb"
      },
      "source": [
        "class InterjectionModel(pl.LightningModule):\n",
        "  def __init__(self, frequency_dim , hidden_dim, batch_size):\n",
        "    super(InterjectionModel, self).__init__()\n",
        "    self.frequency_dim = frequency_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.num_layers = 2\n",
        "    self.lstm = nn.LSTM(input_size=frequency_dim, hidden_size=hidden_dim, num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
        "    self.layer1 = BasicBlock(1,64)\n",
        "    self.layer2 = BasicBlock(64,64)\n",
        "    self.layer3 = conv1x1(64, 1)\n",
        "\n",
        "    self.softmax = nn.LogSoftmax()\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def forward(self, images):\n",
        "    # images.size() = (batch_size × 1 × frequency_dim × hidden_dim)\n",
        "\n",
        "    # images = images.view(self.batch_size, self.frequency_dim, self.hidden_dim)\n",
        "    # images.size() = (batch_size × frequency_dim × hidden_dim)\n",
        "\n",
        "    x = self.layer1(images)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    # x.size() = (batch_size × hidden_dim × hidden_dim)\n",
        "\n",
        "    x = x.view(self.batch_size, self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "    _, lstm_out = self.lstm(x)\n",
        "    # lstm_out[0].size() = ((num_layers × direction)× batch_size × hidden_dim)\n",
        "    last_layer = (self.num_layers - 1) * 2\n",
        "    lstm_out_mean = (lstm_out[0][last_layer] + lstm_out[0][last_layer + 1]) / 2\n",
        "    result = lstm_out_mean.squeeze()\n",
        "    # result.size() = (batch_size × hidden_dim)\n",
        "    return result\n",
        "\n",
        "  def training_step(self, batch, batch_nb):\n",
        "    x, y = batch\n",
        "    y_hat = self(x)\n",
        "    loss = self.criterion(y_hat, y)\n",
        "    self.log('train_loss', loss)\n",
        "    return {'loss': loss}\n",
        "  \n",
        "  def validation_step(self, batch, batch_nb):\n",
        "    x, y = batch\n",
        "    y_hat = self(x)\n",
        "    return {'val_loss': self.criterion(y_hat, y)}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "    self.log('val_loss', avg_loss)\n",
        "\n",
        "  def test_step(self, batch, batch_nb):\n",
        "      x, y = batch\n",
        "      y_hat = self(x)\n",
        "      return {'test_loss': self.criterion(y_hat, y)}\n",
        "\n",
        "  def test_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "    self.log('val_loss', avg_loss, prog_bar=True,)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return optim.Adam(self.parameters(), lr=0.02)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return data.DataLoader(valid_dataset, batch_size=self.batch_size, num_workers=2, drop_last=True)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return data.DataLoader(test_dataset, batch_size=self.batch_size, num_workers=2, drop_last=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAX57gr6SCpp"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33HFZSlFXJ5i",
        "outputId": "bd4d986d-e5b3-40b4-8b5d-5d2b8cd9c2d5"
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass('Enter your private Neptune API token: ')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your private Neptune API token: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9CUPLGIYACs"
      },
      "source": [
        "LightningModule_Params = {'image_size': 512,\n",
        "                          'n_lstm_layer': 2,\n",
        "                          'lstm_bidirection': True,\n",
        "                          'learning_rate': 0.02}\n",
        "\n",
        "LightningDataModule_Params = {'batch_size': BATCH_SIZE,\n",
        "                              'num_workers': 2}\n",
        "\n",
        "LearningRateMonitor_Params = {'logging_interval': 'epoch'}\n",
        "\n",
        "ModelCheckpoint_Params = {'filename': 'my_model/checkpoints/{epoch:02d}-{val_loss:.2f}',\n",
        "                          'save_weights_only': True,\n",
        "                          'monitor': 'val_loss',\n",
        "                          'period': 1}\n",
        "\n",
        "EarlyStopping_Params = {'monitor': 'val_loss'}\n",
        "\n",
        "Trainer_Params = {'log_every_n_steps': 50,\n",
        "                  'max_epochs': 30}\n",
        "\n",
        "\n",
        "\n",
        "ALL_PARAMS = {**LightningModule_Params,\n",
        "              **LightningDataModule_Params,\n",
        "              **LearningRateMonitor_Params,\n",
        "              **EarlyStopping_Params,\n",
        "              **ModelCheckpoint_Params,\n",
        "              **Trainer_Params}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VYxsLoJdHdY",
        "outputId": "c5538b67-3a02-43f3-ce55-a8710c7624ab"
      },
      "source": [
        "neptune_logger = NeptuneLogger(\n",
        "    api_key=api_key,\n",
        "    project_name=\"hourglasshoro/test\",\n",
        "    close_after_fit=False,\n",
        "    experiment_name=\"Test2\",\n",
        "    params=ALL_PARAMS,\n",
        "    tags=['test'],\n",
        "    )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeptuneLogger will work in online mode\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO6t65E6JzSG"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "model = InterjectionModel(512, 512, BATCH_SIZE)\n",
        "early_stop = EarlyStopping(monitor='val_loss')\n",
        "checkpoint = ModelCheckpoint(monitor='val_loss', filename='my_model/checkpoints/{epoch:02d}-{val_loss:.2f}', save_weights_only=True)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=30, gpus=1, callbacks=[early_stop, checkpoint], logger=neptune_logger)    \n",
        "# trainer = pl.Trainer(max_epochs=30, gpus=1, callbacks=[checkpoint], logger=neptune_logger)    \n",
        "trainer.fit(model)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "63c3d94bc45e4ff9aefb48c287039ceb",
            "d0b6e014b638495f8e270ce3a51d737a",
            "b48158f0a575484ab4fa9653b8a908cd",
            "11c4b77f17264c7ab5f0f239851604b4",
            "cf37f7a103214c4f89b774029c68ae1a",
            "3539e3167353419bb626d6d88afaced4",
            "a03bdd272e8941afb424fdd5ee94fe99",
            "d8bef59f72de4183b3507d0a4aaf568e"
          ]
        },
        "id": "Gwd1tdZpUrp1",
        "outputId": "6250709d-b9df-446b-b442-9f32f410784e"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c3d94bc45e4ff9aefb48c287039ceb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'val_loss': 0.54933100938797}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_loss': 0.54933100938797}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etJDgmI4fMUE"
      },
      "source": [
        "neptune_logger.experiment.stop()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQJd8kaDewL3"
      },
      "source": [
        "## Not use Pytorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN1NsRj3BCqT"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self, frequency_dim , hidden_dim, batch_size):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.frequency_dim = frequency_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.batch_size = batch_size\n",
        "    self.lstm = nn.LSTM(input_size=frequency_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
        "    # self.lstm = nn.LSTM(input_size=frequency_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
        "    self.softmax = nn.LogSoftmax()\n",
        "  \n",
        "  def forward(self, images):\n",
        "    # images.size() = (batch_size × 1 × frequency_dim × hidden_dim)\n",
        "    images = images.view(self.batch_size, self.frequency_dim, self.hidden_dim)\n",
        "    # images.size() = (batch_size × frequency_dim × hidden_dim)\n",
        "    _, lstm_out = self.lstm(images)\n",
        "    # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n",
        "    # result = self.softmax(lstm_out[0].squeeze())\n",
        "    # result.size() = (batch_size × hidden_dim)\n",
        "\n",
        "    result = lstm_out[0].squeeze()\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeNcGGycDg8z"
      },
      "source": [
        "model = LSTMClassifier(512, 512, BATCH_SIZE).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Im1FauGDhE",
        "outputId": "6bd73470-2ec7-48c0-dab4-3803ad4e7ed7"
      },
      "source": [
        "for epoch in range(50):\n",
        "  all_loss = 0\n",
        "  train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    num_workers=2, drop_last=True\n",
        "  )\n",
        "  for i , (images, labels) in enumerate(train_dataloader):\n",
        "\n",
        "    # 順伝搬させるtensorはGPUで処理させるためdevice=にGPUをセット\n",
        "    image_tensor = torch.tensor(images, device=device)\n",
        "    # category_tensor.size() = (batch_size × 1)なので、squeeze()\n",
        "    label_tensor = torch.tensor(labels, device=device).squeeze()\n",
        "\n",
        "    out = model(image_tensor)\n",
        "    batch_loss = criterion(out, label_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    all_loss += batch_loss.item()\n",
        "  print(epoch+1, all_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 111.41851443052292\n",
            "2 111.2116351723671\n",
            "3 111.16537064313889\n",
            "4 111.16139322519302\n",
            "5 111.16120076179504\n",
            "6 111.16709697246552\n",
            "7 111.16564673185349\n",
            "8 111.17030203342438\n",
            "9 111.17257761955261\n",
            "10 111.171446621418\n",
            "11 111.17331147193909\n",
            "12 111.17211610078812\n",
            "13 111.17215651273727\n",
            "14 111.17157238721848\n",
            "15 111.17320388555527\n",
            "16 111.1725537776947\n",
            "17 111.17196184396744\n",
            "18 111.17305034399033\n",
            "19 111.17205286026001\n",
            "20 111.1707011461258\n",
            "21 111.14725542068481\n",
            "22 111.14445626735687\n",
            "23 111.1438837647438\n",
            "24 111.14277589321136\n",
            "25 111.14232015609741\n",
            "26 111.14104413986206\n",
            "27 111.14273911714554\n",
            "28 111.14228075742722\n",
            "29 111.14271742105484\n",
            "30 111.14269280433655\n",
            "31 111.14145314693451\n",
            "32 111.14332270622253\n",
            "33 111.1345984339714\n",
            "34 111.11222237348557\n",
            "35 111.1142349243164\n",
            "36 111.11433750391006\n",
            "37 111.11308234930038\n",
            "38 111.11320859193802\n",
            "39 111.11185383796692\n",
            "40 111.11280363798141\n",
            "41 111.11339288949966\n",
            "42 111.11564862728119\n",
            "43 111.11343276500702\n",
            "44 111.11402040719986\n",
            "45 111.11277449131012\n",
            "46 111.11353552341461\n",
            "47 111.11216080188751\n",
            "48 111.11261081695557\n",
            "49 111.11327421665192\n",
            "50 111.1129395365715\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}